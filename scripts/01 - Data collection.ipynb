{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- capire come scrapare meglio user review counts\n",
    "- script con funzioni???\n",
    "\n",
    "- aggiungere table of contents\n",
    "- commentare tutto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGNNMM5OucPo"
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Tq5zlLcDuCkM"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GySk7pbunwY"
   },
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-6kyKK3UprX"
   },
   "source": [
    "IMDB doesn't have an official API. However, there are two unofficial APIs providing access to IMDB data: The Open Movie Database (OMDb) and The Movie Database (TMDB). In this project we'll rely on the latter as it doesn't enforce a rate limit. We're also going to supplement the API data with scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt0ZSUT3Xm3o"
   },
   "source": [
    "The TMDB API works by supplying the ID of the film(s) whose info we'd like to retrieve. The IDs consist of a double \"t\" followed by seven or eight digits. They can be found inside a film URL. For example, \"tt0050782\" is the ID for this film: https://www.imdb.com/title/tt0050782/. \n",
    "\n",
    "The first step will thus be retrieving the IDs of the 5 000 most popular films on IMDB, which can be found in this [playlist](https://www.imdb.com/search/keyword/?mode=detail&page=1&title_type=movie&ref_=kw_ref_rt_vt&num_votes=5000%2C&sort=num_votes,desc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruIEsF-V4A7N"
   },
   "source": [
    "## Scraping the film IDs and the URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN3DXnxMYrbc"
   },
   "source": [
    "To scrape the film IDs of our 5 000 films we'll need to iterate a for loop over the first 100 pages in the playlist (each containing 50 films). The film ID is the value of the 'href' attribute inside h3 elements with the \"lister-item-header\" class. We'll write a simple regex to extract the film ID. We'll also scrape the entire URL: it's going to come in handy later when we do the scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N0QXTJHZwTUc"
   },
   "outputs": [],
   "source": [
    "film_ids = []\n",
    "film_urls = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "  \n",
    "  content = requests.get(f\"https://www.imdb.com/search/keyword/?mode=detail&page={i}&title_type=movie&ref_=kw_ref_rt_vt&num_votes=5000%2C&sort=num_votes,desc\").content\n",
    "  \n",
    "  soup = BeautifulSoup(content)\n",
    "\n",
    "  for film in soup.find_all(\"h3\", class_=\"lister-item-header\"):\n",
    "\n",
    "    link = film.find(\"a\").get(\"href\")\n",
    "    film_id = re.findall(pattern = r\"tt\\d+\", string = link)[0]\n",
    "    film_ids.append(film_id)\n",
    "\n",
    "    film_url = \"https://www.imdb.com\" + link\n",
    "    film_urls.append(film_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GwT4Wuv61we"
   },
   "source": [
    "## API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51KySz-jZsxT"
   },
   "source": [
    "We'll now write a function to request the data from TMDB. The function takes a vector of film IDs as input and it returns a dataframe. For each ID it sends a GET request to the API. If the status code is equal to 200 (i.e. the request has been successful) it appends the data to a Pandas dataframe. Otherwise, it just appends the film_id and fills the remaining columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Pn5hoWsWdNZZ"
   },
   "outputs": [],
   "source": [
    "def build_film_df(film_ids):\n",
    "    \n",
    "  api_key = os.environ.get(\"tmdb_api_key\")\n",
    "\n",
    "  df = pd.DataFrame(columns = [\"id\", \"title\", \"release_date\", \"runtime\", \"country\", \"language\", \n",
    "                               \"genre\", \"studios\", \"budget\", \"revenue\"])\n",
    "\n",
    "  for film_id in film_ids:\n",
    "      \n",
    "      response = requests.get(f\"https://api.themoviedb.org/3/movie/{film_id}?api_key={api_key}\")\n",
    "\n",
    "      if response.status_code == 200:  \n",
    "\n",
    "        response_json = response.json()\n",
    "\n",
    "        df = df.append({\"id\": response_json[\"imdb_id\"],\n",
    "                        \"title\": response_json[\"title\"],\n",
    "                        \"release_date\": response_json[\"release_date\"],\n",
    "                        \"runtime\": response_json[\"runtime\"],\n",
    "                        \"country\": ';'.join([country['name'] for country in response_json[\"production_countries\"]]),\n",
    "                        \"language\": ';'.join([language[\"english_name\"] for language in response_json[\"spoken_languages\"]]),\n",
    "                        \"genre\": ';'.join([genre[\"name\"] for genre in response_json[\"genres\"]]),\n",
    "                        \"studios\": ';'.join([company[\"name\"] for company in response_json['production_companies']]),\n",
    "                        \"budget\": response_json['budget'],\n",
    "                        \"revenue\": response_json[\"revenue\"]}, \n",
    "                        ignore_index = True)\n",
    "        \n",
    "      else:\n",
    "        df = df.append({\"id\": film_id}, ignore_index = True)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on the film IDs we just scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "ckKclT-ouHfd",
    "outputId": "d438579e-4d83-4c41-aad8-e53f0c02135b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>studios</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>142</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama;Crime</td>\n",
       "      <td>Castle Rock Entertainment</td>\n",
       "      <td>25000000</td>\n",
       "      <td>28341469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008-07-14</td>\n",
       "      <td>152</td>\n",
       "      <td>United Kingdom;United States of America</td>\n",
       "      <td>English;Mandarin</td>\n",
       "      <td>Drama;Action;Crime;Thriller</td>\n",
       "      <td>DC Comics;Legendary Pictures;Syncopy;Isobel Gr...</td>\n",
       "      <td>185000000</td>\n",
       "      <td>1004558444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>148</td>\n",
       "      <td>United Kingdom;United States of America</td>\n",
       "      <td>English;Japanese</td>\n",
       "      <td>Action;Science Fiction;Adventure</td>\n",
       "      <td>Legendary Pictures;Syncopy;Warner Bros. Pictures</td>\n",
       "      <td>160000000</td>\n",
       "      <td>825532764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0137523</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999-10-15</td>\n",
       "      <td>139</td>\n",
       "      <td>Germany;United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Regency Enterprises;Fox 2000 Pictures;Taurus F...</td>\n",
       "      <td>63000000</td>\n",
       "      <td>100853753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994-07-06</td>\n",
       "      <td>142</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Comedy;Drama;Romance</td>\n",
       "      <td>Paramount;The Steve Tisch Company</td>\n",
       "      <td>55000000</td>\n",
       "      <td>677387716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     title release_date runtime  \\\n",
       "0  tt0111161  The Shawshank Redemption   1994-09-23     142   \n",
       "1  tt0468569           The Dark Knight   2008-07-14     152   \n",
       "2  tt1375666                 Inception   2010-07-15     148   \n",
       "3  tt0137523                Fight Club   1999-10-15     139   \n",
       "4  tt0109830              Forrest Gump   1994-07-06     142   \n",
       "\n",
       "                                   country          language  \\\n",
       "0                 United States of America           English   \n",
       "1  United Kingdom;United States of America  English;Mandarin   \n",
       "2  United Kingdom;United States of America  English;Japanese   \n",
       "3         Germany;United States of America           English   \n",
       "4                 United States of America           English   \n",
       "\n",
       "                              genre  \\\n",
       "0                       Drama;Crime   \n",
       "1       Drama;Action;Crime;Thriller   \n",
       "2  Action;Science Fiction;Adventure   \n",
       "3                             Drama   \n",
       "4              Comedy;Drama;Romance   \n",
       "\n",
       "                                             studios     budget     revenue  \n",
       "0                          Castle Rock Entertainment   25000000    28341469  \n",
       "1  DC Comics;Legendary Pictures;Syncopy;Isobel Gr...  185000000  1004558444  \n",
       "2   Legendary Pictures;Syncopy;Warner Bros. Pictures  160000000   825532764  \n",
       "3  Regency Enterprises;Fox 2000 Pictures;Taurus F...   63000000   100853753  \n",
       "4                  Paramount;The Steve Tisch Company   55000000   677387716  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = build_film_df(film_ids)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_api.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VroIT9ExpVtY"
   },
   "source": [
    "## Scraping additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOgUWYm7bRqV"
   },
   "source": [
    "TMDB API has some limits: it doesn't provide data about the people who worked on a film (directors, writer, actors etc.) and its rating data is inaccurate. We'll thus integrate the data we just got by scraping some more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdfF63LCTwRi"
   },
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KytHOgpT0HC"
   },
   "source": [
    "To implement sound software engineering principles we'll scrape the data by building a function for each type of data we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdS235LCUFDf"
   },
   "source": [
    "#### Film ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nNSWeewsQ3Gt"
   },
   "outputs": [],
   "source": [
    "def scrape_film_id(soup):\n",
    "    \n",
    "    try:\n",
    "        film_id = soup.find(\"meta\", {\"property\": \"imdb:pageConst\"}).get(\"content\")\n",
    "    except:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return film_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WpHvI39UHtL"
   },
   "source": [
    "#### Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zwLDT6CW1tL0"
   },
   "outputs": [],
   "source": [
    "def scrape_director(soup):\n",
    "    \n",
    "    try:  \n",
    "        a_tags = soup.find_all(href = re.compile(\"tt_ov_dr\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "    \n",
    "        directors = list(set([a.text for a in a_tags]))\n",
    "    \n",
    "        directors = ';'.join(directors)\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_writer(soup):\n",
    "    \n",
    "    try:\n",
    "        a_tags = soup.find_all(href = re.compile(\"tt_ov_wr\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "        \n",
    "        writers = list(set([a.text for a in a_tags]))\n",
    "        \n",
    "        writers = ';'.join(writers)\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY0xRacoUKxG"
   },
   "source": [
    "#### IMDB average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GHuWP7Pe8EHq"
   },
   "outputs": [],
   "source": [
    "def scrape_imdb_rating(soup):\n",
    "    \n",
    "    try:   \n",
    "        span = soup.find_all(\"span\", class_=\"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\")[0]\n",
    "    \n",
    "        imdb_rating = span.text\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return imdb_rating\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63sBX-TwUN1q"
   },
   "source": [
    "#### IMDB rating count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7u68JHWr_1oe"
   },
   "outputs": [],
   "source": [
    "def scrape_rating_count(soup):\n",
    "    \n",
    "    try:\n",
    "        pattern = r'(?<=\"ratingCount\":)[\\d.]+'\n",
    "        string = str(soup.find(\"script\", {\"type\": \"application/ld+json\"}))\n",
    "        rating_count = re.findall(pattern = pattern, string = string)[0]\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return rating_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne8ybLy_UPrk"
   },
   "source": [
    "#### Metascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HzWpD51AAhe5"
   },
   "outputs": [],
   "source": [
    "def scrape_metascore(soup):\n",
    "    \n",
    "    try:\n",
    "        metascore = soup.find(\"span\", class_=\"score-meta\").text \n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return metascore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YwH147RUSXB"
   },
   "source": [
    "#### User review count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PLb_JqIRnKls"
   },
   "outputs": [],
   "source": [
    "def scrape_user_review_count(soup):\n",
    "    \n",
    "    try: \n",
    "        pattern = r'(?<=\"total\":)\\d+(?=,\"__typename\":\"ReviewsConnection\"},\"criticReviewsTotal\":)'\n",
    "  \n",
    "        string = str(soup.find(\"script\", {'id': '__NEXT_DATA__'}))\n",
    "    \n",
    "        user_review_count = re.findall(pattern = pattern, string = string)[0]\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return user_review_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0WXIPIWUWHl"
   },
   "source": [
    "#### Critic review count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_critic_review_count(soup):\n",
    "    \n",
    "    try:   \n",
    "        spans = soup.find_all(\"span\", class_= re.compile(\"three-Elements\")) \n",
    "        \n",
    "        string = list(filter(lambda x: 'Critic' in str(x), spans))[0].text\n",
    "        \n",
    "        critic_review_count = re.findall(r'\\d+', string)[0]\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return critic_review_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_color(soup):\n",
    "    \n",
    "    try:\n",
    "        pattern = r'(?<=\"text\":\")\\w+(?=\",\"attributes\":\\[\\],\"__typename\":\"Coloration\"})'\n",
    "        \n",
    "        string = str(soup.find(\"script\", {\"type\": \"application/json\"}))\n",
    "    \n",
    "        color = re.findall(pattern = pattern, string = string)[0]\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_aspect_ratio(soup):\n",
    "    try:\n",
    "        pattern = r'(?<=\"aspectRatio\":\")[\\d.\\s:]+'\n",
    "    \n",
    "        string = str(soup.find(\"script\", {\"type\": \"application/json\"}))\n",
    "    \n",
    "        aspect_ratio = re.findall(pattern = pattern, string = string)[0] \n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return aspect_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRaqDP82V4Xh"
   },
   "source": [
    "### Creating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-PuxtrS5V8IQ"
   },
   "outputs": [],
   "source": [
    "def build_scraped_df(urls):\n",
    "\n",
    "  df = pd.DataFrame(columns = [\"id\", \"director\", \"writer\", \"imdb_rating\", \"imdb_rating_count\", \"metascore\", \n",
    "                               \"user_review_count\", \"critic_review_count\", \"color\", \"aspect_ratio\"])\n",
    "\n",
    "  for url in urls:\n",
    "        \n",
    "        session = requests.Session()\n",
    "        retry = Retry(total = 30, backoff_factor = 0.000001)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('http://', adapter)\n",
    "        session.mount('https://', adapter)\n",
    "        content = session.get(url).content\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        df = df.append({\"id\": scrape_film_id(soup),\n",
    "                        \"director\": scrape_director(soup),\n",
    "                        \"writer\": scrape_writer(soup),\n",
    "                        \"imdb_rating\": scrape_imdb_rating(soup),\n",
    "                        \"imdb_rating_count\": scrape_rating_count(soup),\n",
    "                        \"metascore\": scrape_metascore(soup),\n",
    "                        \"user_review_count\": scrape_user_review_count(soup),\n",
    "                        \"critic_review_count\": scrape_critic_review_count(soup),\n",
    "                        \"color\": scrape_color(soup),\n",
    "                        \"aspect_ratio\": scrape_aspect_ratio(soup)}, \n",
    "                        ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on the film URLs we scraped at 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Sqmef_HbZ6fi",
    "outputId": "a5e98cbb-4ae7-4444-9e39-bfe70225c3d4"
   },
   "outputs": [],
   "source": [
    "df2 = build_scraped_df(film_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Sqmef_HbZ6fi",
    "outputId": "a5e98cbb-4ae7-4444-9e39-bfe70225c3d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>imdb_rating_count</th>\n",
       "      <th>metascore</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>critic_review_count</th>\n",
       "      <th>color</th>\n",
       "      <th>aspect_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>Stephen King;Frank Darabont</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2506833</td>\n",
       "      <td>80</td>\n",
       "      <td>9750</td>\n",
       "      <td>190</td>\n",
       "      <td>Color</td>\n",
       "      <td>1.85 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>David S. Goyer;Jonathan Nolan;Christopher Nolan</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2456425</td>\n",
       "      <td>84</td>\n",
       "      <td>7764</td>\n",
       "      <td>427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2203914</td>\n",
       "      <td>74</td>\n",
       "      <td>4466</td>\n",
       "      <td>479</td>\n",
       "      <td>Color</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0137523</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>Jim Uhls;Chuck Palahniuk</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1971788</td>\n",
       "      <td>66</td>\n",
       "      <td>4127</td>\n",
       "      <td>366</td>\n",
       "      <td>Color</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>Winston Groom;Eric Roth</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1934719</td>\n",
       "      <td>82</td>\n",
       "      <td>2807</td>\n",
       "      <td>164</td>\n",
       "      <td>Color</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           director  \\\n",
       "0  tt0111161     Frank Darabont   \n",
       "1  tt0468569  Christopher Nolan   \n",
       "2  tt1375666  Christopher Nolan   \n",
       "3  tt0137523      David Fincher   \n",
       "4  tt0109830    Robert Zemeckis   \n",
       "\n",
       "                                            writer imdb_rating  \\\n",
       "0                      Stephen King;Frank Darabont         9.3   \n",
       "1  David S. Goyer;Jonathan Nolan;Christopher Nolan         9.0   \n",
       "2                                Christopher Nolan         8.8   \n",
       "3                         Jim Uhls;Chuck Palahniuk         8.8   \n",
       "4                          Winston Groom;Eric Roth         8.8   \n",
       "\n",
       "  imdb_rating_count metascore user_review_count critic_review_count  color  \\\n",
       "0           2506833        80              9750                 190  Color   \n",
       "1           2456425        84              7764                 427    NaN   \n",
       "2           2203914        74              4466                 479  Color   \n",
       "3           1971788        66              4127                 366  Color   \n",
       "4           1934719        82              2807                 164  Color   \n",
       "\n",
       "  aspect_ratio  \n",
       "0     1.85 : 1  \n",
       "1     2.39 : 1  \n",
       "2     2.39 : 1  \n",
       "3     2.39 : 1  \n",
       "4     2.39 : 1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"data/scraped_df_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping people data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, TMDB API doesn't provide much data about the people who worked on a film, so we'll need to scrape that data ourselves. These pieces of info aren't located in the regular film pages but in the \"Full cast and crew\" pages. So before scraping the data we first need to collect all these pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_pages = []\n",
    "\n",
    "for url in film_urls:\n",
    "    \n",
    "    try:   \n",
    "        \n",
    "        session = requests.Session()\n",
    "        retry = Retry(total = 30, backoff_factor = 0.000001)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('http://', adapter)\n",
    "        session.mount('https://', adapter)\n",
    "        \n",
    "        content = session.get(url).content\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        a_target = soup.find(href = re.compile(\"tt_cl_sm\"), class_=\"ipc-metadata-list-item__label ipc-metadata-list-item__label--link\")\n",
    "        \n",
    "        crew_page = \"https://www.imdb.com\" + a_target.get(\"href\")\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        crew_pages.append(crew_page)   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/crew_pages_urls.txt\", \"wb\") as opened_file:\n",
    "    pickle.dump(crew_pages, opened_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQtgCMgbUgCS"
   },
   "source": [
    "#### Full cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the artists can be found inside the table with the \"cast-list\" class: they're the alternative text of the images inside the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_actors(soup):\n",
    "    \n",
    "    try:   \n",
    "        images = soup.find(\"table\", class_=\"cast_list\").find_all(\"img\") \n",
    "        \n",
    "        actors = [img.get(\"alt\") for img in images]  \n",
    "        \n",
    "        actors = ';'.join(actors)\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cinematographer, editor, composer, producers, production designer, art director, costume designer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function scrapes the names of different types of artists. The type must be specified in the 'artist' argument. \n",
    "\n",
    "In the \"Full Cast & Crew\" pages each artist type has its own table element containing the names of the artists. Each of these tables is preceded by an h4 element with an id equal to the artist type. For example, the name of the cinematographer is contained in the table preceded by the h4 element with id equal to \"cinematographer\". To scrape this data, we'll first access the h4 element, then we'll access the table next to it and finally we'll get all the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_artist(soup, artist):\n",
    "    \n",
    "    try:\n",
    "        h = soup.find(\"h4\", id = artist)\n",
    "        \n",
    "        a_tags = h.find_next(\"table\").find_all(\"a\")\n",
    "        \n",
    "        artists = [a.text.lstrip().replace('\\n', '') for a in a_tags]\n",
    "        \n",
    "        artists = ';'.join(artists)\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:     \n",
    "        return artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again we'll split the list of urls into 5 equally-sized chunks and wait 5 mins between each chunk so as not to clutter the IMDB website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scraped_df_2(urls):\n",
    "    \n",
    "    df = pd.DataFrame(columns = [\"id\", \"actors\", \"cinematographer\", \"editor\", \"composer\", \"producers\", \"production_designer\",\n",
    "                                \"art_director\", \"costume_designer\"])\n",
    "    \n",
    "    for url in urls:\n",
    "        session = requests.Session()\n",
    "        retry = Retry(total = 30, backoff_factor = 0.000001)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('http://', adapter)\n",
    "        session.mount('https://', adapter)\n",
    "        \n",
    "        content = session.get(url).content\n",
    "        soup = BeautifulSoup(content)\n",
    "            \n",
    "        df = df.append({\"id\": re.findall(r\"tt\\d+\", url)[0],\n",
    "                        \"actors\": scrape_actors(soup),\n",
    "                        \"cinematographer\": scrape_artist(soup, \"cinematographer\"),\n",
    "                        \"editor\": scrape_artist(soup, \"editor\"),\n",
    "                        \"composer\": scrape_artist(soup, \"composer\"),\n",
    "                        \"producers\": scrape_artist(soup, \"producer\"),\n",
    "                        \"production_designer\": scrape_artist(soup, \"production_designer\"),\n",
    "                        \"art_director\": scrape_artist(soup, \"art_director\"),\n",
    "                        \"costume_designer\": scrape_artist(soup, \"costume_designer\")},\n",
    "                        ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on our list of 'Full cast and crew' pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = build_scraped_df_2(crew_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.head(10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Building a database of IMDB 10,000 most popular feature films.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
