{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Modules](#chapter1)\n",
    "2. [Scraping the IDs and the URLs](#chapter2)\n",
    "3. [API calls](#chapters3)\n",
    "4. [Scraping additional data](#chapter4)\n",
    "    1. [Custom functions](#subparagraph1)\n",
    "    2. [Creating the dataframe](#subgraph2)\n",
    "5. [Scraping people data](#chapter5)\n",
    "    1. [Custom functions](#subparagraph3)\n",
    "    2. [Creating the dataframe](#subparagraph4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGNNMM5OucPo"
   },
   "source": [
    "# Modules <a class=\"anchor\" id=\"chapter1\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tq5zlLcDuCkM"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruIEsF-V4A7N"
   },
   "source": [
    "# Scraping the film IDs and the URLs <a class=\"anchor\" id=\"chapter2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-6kyKK3UprX"
   },
   "source": [
    "IMDB doesn't have an API. However, there are two unofficial IMDBI APIs: The Open Movie Database (OMDb) and The Movie Database (TMDB). In this project we'll rely on the latter as it doesn't enforce a rate limit. We're also going to supplement the API data with scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt0ZSUT3Xm3o"
   },
   "source": [
    "TMDB API works by supplying the ID of the film(s) whose info we'd like to retrieve. The IDs consist of a double \"t\" followed by seven or eight digits. They can be found inside a film URL. For example, \"tt0050782\" is the ID for this film: https://www.imdb.com/title/tt0050782/. \n",
    "\n",
    "The first step will thus be retrieving the IDs of the 5 000 most popular films on IMDB, which can be found in this [playlist](https://www.imdb.com/search/keyword/?mode=detail&page=1&title_type=movie&ref_=kw_ref_rt_vt&num_votes=5000%2C&sort=num_votes,desc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN3DXnxMYrbc"
   },
   "source": [
    "To scrape the film IDs of our 5 000 films we'll need to iterate a for loop over the first 100 pages in the playlist (each containing 50 films). The film ID is the value of the 'href' attribute inside h3 elements with the \"lister-item-header\" class. We'll write a simple regex to extract the film ID. We'll also scrape the entire URL: it's going to come in handy later when we do the scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N0QXTJHZwTUc"
   },
   "outputs": [],
   "source": [
    "film_ids = []\n",
    "film_urls = []\n",
    "\n",
    "for i in range(1, 101):\n",
    "  \n",
    "  content = requests.get(f\"https://www.imdb.com/search/keyword/?mode=detail&page={i}&title_type=movie&ref_=kw_ref_rt_vt&num_votes=5000%2C&sort=num_votes,desc\").content\n",
    "  \n",
    "  soup = BeautifulSoup(content)\n",
    "\n",
    "  for film in soup.find_all(\"h3\", class_=\"lister-item-header\"):\n",
    "\n",
    "    link = film.find(\"a\").get(\"href\")\n",
    "    film_id = re.findall(pattern = r\"tt\\d+\", string = link)[0]\n",
    "    film_ids.append(film_id)\n",
    "\n",
    "    film_url = \"https://www.imdb.com\" + link\n",
    "    film_urls.append(film_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GwT4Wuv61we"
   },
   "source": [
    "# API calls <a class=\"anchor\" id=\"chapter3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51KySz-jZsxT"
   },
   "source": [
    "We'll now write a function to request the data from TMDB. The function takes a vector of film IDs as input and it returns a dataframe. For each ID it sends a GET request to the API. If the status code is equal to 200 (i.e. the request has been successful) it appends the data to a Pandas dataframe. Otherwise, it just appends the film_id and fills the remaining columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Pn5hoWsWdNZZ"
   },
   "outputs": [],
   "source": [
    "def build_film_df(film_ids):\n",
    "    \n",
    "  api_key = os.environ.get(\"tmdb_api_key\")\n",
    "\n",
    "  df = pd.DataFrame(columns = [\"id\", \"title\", \"release_date\", \"runtime\", \"country\", \"language\", \n",
    "                               \"genre\", \"studios\", \"budget\", \"revenue\"])\n",
    "\n",
    "  for film_id in film_ids:\n",
    "      \n",
    "      response = requests.get(f\"https://api.themoviedb.org/3/movie/{film_id}?api_key={api_key}\")\n",
    "\n",
    "      if response.status_code == 200:  \n",
    "\n",
    "        response_json = response.json()\n",
    "\n",
    "        df = df.append({\"id\": response_json[\"imdb_id\"],\n",
    "                        \"title\": response_json[\"title\"],\n",
    "                        \"release_date\": response_json[\"release_date\"],\n",
    "                        \"runtime\": response_json[\"runtime\"],\n",
    "                        \"country\": ';'.join([country['name'] for country in response_json[\"production_countries\"]]),\n",
    "                        \"language\": ';'.join([language[\"english_name\"] for language in response_json[\"spoken_languages\"]]),\n",
    "                        \"genre\": ';'.join([genre[\"name\"] for genre in response_json[\"genres\"]]),\n",
    "                        \"studios\": ';'.join([company[\"name\"] for company in response_json['production_companies']]),\n",
    "                        \"budget\": response_json['budget'],\n",
    "                        \"revenue\": response_json[\"revenue\"]}, \n",
    "                        ignore_index = True)\n",
    "        \n",
    "      else:\n",
    "        df = df.append({\"id\": film_id}, ignore_index = True)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on the film IDs we just scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "ckKclT-ouHfd",
    "outputId": "d438579e-4d83-4c41-aad8-e53f0c02135b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>studios</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>142</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama;Crime</td>\n",
       "      <td>Castle Rock Entertainment</td>\n",
       "      <td>25000000</td>\n",
       "      <td>28341469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008-07-14</td>\n",
       "      <td>152</td>\n",
       "      <td>United Kingdom;United States of America</td>\n",
       "      <td>English;Mandarin</td>\n",
       "      <td>Drama;Action;Crime;Thriller</td>\n",
       "      <td>DC Comics;Legendary Pictures;Syncopy;Isobel Gr...</td>\n",
       "      <td>185000000</td>\n",
       "      <td>1004558444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>148</td>\n",
       "      <td>United Kingdom;United States of America</td>\n",
       "      <td>English;Japanese</td>\n",
       "      <td>Action;Science Fiction;Adventure</td>\n",
       "      <td>Legendary Pictures;Syncopy;Warner Bros. Pictures</td>\n",
       "      <td>160000000</td>\n",
       "      <td>825532764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0137523</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999-10-15</td>\n",
       "      <td>139</td>\n",
       "      <td>Germany;United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Regency Enterprises;Fox 2000 Pictures;Taurus F...</td>\n",
       "      <td>63000000</td>\n",
       "      <td>100853753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994-07-06</td>\n",
       "      <td>142</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Comedy;Drama;Romance</td>\n",
       "      <td>Paramount;The Steve Tisch Company</td>\n",
       "      <td>55000000</td>\n",
       "      <td>677387716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     title release_date runtime  \\\n",
       "0  tt0111161  The Shawshank Redemption   1994-09-23     142   \n",
       "1  tt0468569           The Dark Knight   2008-07-14     152   \n",
       "2  tt1375666                 Inception   2010-07-15     148   \n",
       "3  tt0137523                Fight Club   1999-10-15     139   \n",
       "4  tt0109830              Forrest Gump   1994-07-06     142   \n",
       "\n",
       "                                   country          language  \\\n",
       "0                 United States of America           English   \n",
       "1  United Kingdom;United States of America  English;Mandarin   \n",
       "2  United Kingdom;United States of America  English;Japanese   \n",
       "3         Germany;United States of America           English   \n",
       "4                 United States of America           English   \n",
       "\n",
       "                              genre  \\\n",
       "0                       Drama;Crime   \n",
       "1       Drama;Action;Crime;Thriller   \n",
       "2  Action;Science Fiction;Adventure   \n",
       "3                             Drama   \n",
       "4              Comedy;Drama;Romance   \n",
       "\n",
       "                                             studios     budget     revenue  \n",
       "0                          Castle Rock Entertainment   25000000    28341469  \n",
       "1  DC Comics;Legendary Pictures;Syncopy;Isobel Gr...  185000000  1004558444  \n",
       "2   Legendary Pictures;Syncopy;Warner Bros. Pictures  160000000   825532764  \n",
       "3  Regency Enterprises;Fox 2000 Pictures;Taurus F...   63000000   100853753  \n",
       "4                  Paramount;The Steve Tisch Company   55000000   677387716  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = build_film_df(film_ids)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it as a .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_api.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VroIT9ExpVtY"
   },
   "source": [
    "# Scraping additional data <a class=\"anchor\" id=\"chapter4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOgUWYm7bRqV"
   },
   "source": [
    "TMDB API has some limits: it doesn't provide data about the people who worked on a film (directors, writer, actors etc.) and its rating data is inaccurate. We'll thus integrate the data we just got by scraping some more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdfF63LCTwRi"
   },
   "source": [
    "## Custom functions <a class=\"anchor\" id=\"subparagraph1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KytHOgpT0HC"
   },
   "source": [
    "To implement sound software engineering principles we'll scrape the data by building a function for each type of data we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdS235LCUFDf"
   },
   "source": [
    "### Film ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the film ID, we'll first access the 'meta' tag with property equal to 'imdb:pageConst' and then we'll get the value of the 'content' attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nNSWeewsQ3Gt"
   },
   "outputs": [],
   "source": [
    "def scrape_film_id(soup):\n",
    "    \n",
    "    try:\n",
    "        film_id = soup.find(\"meta\", {\"property\": \"imdb:pageConst\"}).get(\"content\")\n",
    "    except:\n",
    "        return np.nan\n",
    "    else:\n",
    "        return film_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WpHvI39UHtL"
   },
   "source": [
    "### Directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the directors we'll access all the href tags containing the 'tt_ov_dr' regex and with classes equal to \"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\". The resulting list contains duplicated values, so we'll turn it into a set to keep only distinct values. We'll finally turn it back into a list which we'll collapse into a single string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zwLDT6CW1tL0"
   },
   "outputs": [],
   "source": [
    "def scrape_director(soup):\n",
    "    \n",
    "    try:  \n",
    "        a_tags = soup.find_all(href = re.compile(\"tt_ov_dr\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "    \n",
    "        directors = list(set([a.text for a in a_tags]))\n",
    "    \n",
    "        directors = ';'.join(directors)\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before but this time we're looking for href tags containing the 'tt_ov_wr' regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_writer(soup):\n",
    "    \n",
    "    try:\n",
    "        a_tags = soup.find_all(href = re.compile(\"tt_ov_wr\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "        \n",
    "        writers = list(set([a.text for a in a_tags]))\n",
    "        \n",
    "        writers = ';'.join(writers)\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return writers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY0xRacoUKxG"
   },
   "source": [
    "### IMDB average rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rating can be found as the text of the first span tag with class equal to 'AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "GHuWP7Pe8EHq"
   },
   "outputs": [],
   "source": [
    "def scrape_imdb_rating(soup):\n",
    "    \n",
    "    try:   \n",
    "        span = soup.find_all(\"span\", class_=\"AggregateRatingButton__RatingScore-sc-1ll29m0-1 iTLWoV\")[0]\n",
    "    \n",
    "        imdb_rating = span.text\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return imdb_rating\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63sBX-TwUN1q"
   },
   "source": [
    "### IMDB rating count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To scrape the rating count we need to get a little creative. This value can be found in the 'script' tag with type equal to 'application/ld+json': it's preceded by '\"ratingCount\":'. If we treat the whole tag as string, we can extract it with a positive lookbehind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "7u68JHWr_1oe"
   },
   "outputs": [],
   "source": [
    "def scrape_rating_count(soup):\n",
    "    \n",
    "    try:\n",
    "        pattern = r'(?<=\"ratingCount\":)[\\d.]+'\n",
    "        string = str(soup.find(\"script\", {\"type\": \"application/ld+json\"}))\n",
    "        rating_count = re.findall(pattern = pattern, string = string)[0]\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return rating_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne8ybLy_UPrk"
   },
   "source": [
    "### Metascore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'span' tag with the 'score-meta' class contains the Metascore of the film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HzWpD51AAhe5"
   },
   "outputs": [],
   "source": [
    "def scrape_metascore(soup):\n",
    "    \n",
    "    try:\n",
    "        metascore = soup.find(\"span\", class_=\"score-meta\").text \n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return metascore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YwH147RUSXB"
   },
   "source": [
    "### User review count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract the number of user reviews by treating the 'script' tag with id equal to '__NEXT_DATA__' as a string and by using a regex with both a lookbehind and a lookahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "PLb_JqIRnKls"
   },
   "outputs": [],
   "source": [
    "def scrape_user_review_count(soup):\n",
    "    \n",
    "    try: \n",
    "        pattern = r'(?<=\"total\":)\\d+(?=,\"__typename\":\"ReviewsConnection\"},\"criticReviewsTotal\":)'\n",
    "  \n",
    "        string = str(soup.find(\"script\", {'id': '__NEXT_DATA__'}))\n",
    "    \n",
    "        user_review_count = re.findall(pattern = pattern, string = string)[0]\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return user_review_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0WXIPIWUWHl"
   },
   "source": [
    "### Critic review count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To retrieve the number of critic reviews we'll first access all the 'span' tags assigned to a class containing the 'three-Elements' regex and then filter the resulting list by only keeping the 'span' tag containing the word 'Critic'. Finally we'll use a very simple regex to extract the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_critic_review_count(soup):\n",
    "    \n",
    "    try:   \n",
    "        spans = soup.find_all(\"span\", class_= re.compile(\"three-Elements\")) \n",
    "        \n",
    "        string = list(filter(lambda x: 'Critic' in str(x), spans))[0].text\n",
    "        \n",
    "        critic_review_count = re.findall(r'\\d+', string)[0]\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return critic_review_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to what we did for the rating count and the user review count, we're going to use a positive lookbehind and a positive lookahead to scrape the 'Color' value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_color(soup):\n",
    "    \n",
    "    try:\n",
    "        pattern = r'(?<=\"text\":\")\\w+(?=\",\"attributes\":\\[\\],\"__typename\":\"Coloration\"})'\n",
    "        \n",
    "        string = str(soup.find(\"script\", {\"type\": \"application/json\"}))\n",
    "    \n",
    "        color = re.findall(pattern = pattern, string = string)[0]\n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aspect ratio will be scraped similarly by using a positive lookbehind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_aspect_ratio(soup):\n",
    "    try:\n",
    "        pattern = r'(?<=\"aspectRatio\":\")[\\d.\\s:]+'\n",
    "    \n",
    "        string = str(soup.find(\"script\", {\"type\": \"application/json\"}))\n",
    "    \n",
    "        aspect_ratio = re.findall(pattern = pattern, string = string)[0] \n",
    "        \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:\n",
    "        return aspect_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRaqDP82V4Xh"
   },
   "source": [
    "## Creating the dataframe <a class=\"anchor\" id=\"subparagraph2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create a dataframe of scraped data by iterating over a list of URLs and by appending each scraped value to a column of the df. Should we got an error while scraping, we're ll retry up to 3 times by waiting approximately 9 minutes between each try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-PuxtrS5V8IQ"
   },
   "outputs": [],
   "source": [
    "def build_scraped_df(urls):\n",
    "\n",
    "  df = pd.DataFrame(columns = [\"id\", \"director\", \"writer\", \"imdb_rating\", \"imdb_rating_count\", \"metascore\", \n",
    "                               \"user_review_count\", \"critic_review_count\", \"color\", \"aspect_ratio\"])\n",
    "\n",
    "  for url in urls:\n",
    "        \n",
    "        session = requests.Session()\n",
    "        retry = Retry(total = 30, backoff_factor = 0.000001)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('http://', adapter)\n",
    "        session.mount('https://', adapter)\n",
    "        content = session.get(url).content\n",
    "        soup = BeautifulSoup(content)\n",
    "        \n",
    "        df = df.append({\"id\": scrape_film_id(soup),\n",
    "                        \"director\": scrape_director(soup),\n",
    "                        \"writer\": scrape_writer(soup),\n",
    "                        \"imdb_rating\": scrape_imdb_rating(soup),\n",
    "                        \"imdb_rating_count\": scrape_rating_count(soup),\n",
    "                        \"metascore\": scrape_metascore(soup),\n",
    "                        \"user_review_count\": scrape_user_review_count(soup),\n",
    "                        \"critic_review_count\": scrape_critic_review_count(soup),\n",
    "                        \"color\": scrape_color(soup),\n",
    "                        \"aspect_ratio\": scrape_aspect_ratio(soup)}, \n",
    "                        ignore_index = True)\n",
    "\n",
    "\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on the film URLs we scraped at 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Sqmef_HbZ6fi",
    "outputId": "a5e98cbb-4ae7-4444-9e39-bfe70225c3d4"
   },
   "outputs": [],
   "source": [
    "df2 = build_scraped_df(film_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Sqmef_HbZ6fi",
    "outputId": "a5e98cbb-4ae7-4444-9e39-bfe70225c3d4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>director</th>\n",
       "      <th>writer</th>\n",
       "      <th>imdb_rating</th>\n",
       "      <th>imdb_rating_count</th>\n",
       "      <th>metascore</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>critic_review_count</th>\n",
       "      <th>color</th>\n",
       "      <th>aspect_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>Frank Darabont</td>\n",
       "      <td>Stephen King;Frank Darabont</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2506833</td>\n",
       "      <td>80</td>\n",
       "      <td>9750</td>\n",
       "      <td>190</td>\n",
       "      <td>Color</td>\n",
       "      <td>1.85 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>David S. Goyer;Jonathan Nolan;Christopher Nolan</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2456425</td>\n",
       "      <td>84</td>\n",
       "      <td>7764</td>\n",
       "      <td>427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>Christopher Nolan</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2203914</td>\n",
       "      <td>74</td>\n",
       "      <td>4466</td>\n",
       "      <td>479</td>\n",
       "      <td>Color</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0137523</td>\n",
       "      <td>David Fincher</td>\n",
       "      <td>Jim Uhls;Chuck Palahniuk</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1971788</td>\n",
       "      <td>66</td>\n",
       "      <td>4127</td>\n",
       "      <td>366</td>\n",
       "      <td>Color</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "      <td>Winston Groom;Eric Roth</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1934719</td>\n",
       "      <td>82</td>\n",
       "      <td>2807</td>\n",
       "      <td>164</td>\n",
       "      <td>Color</td>\n",
       "      <td>2.39 : 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id           director  \\\n",
       "0  tt0111161     Frank Darabont   \n",
       "1  tt0468569  Christopher Nolan   \n",
       "2  tt1375666  Christopher Nolan   \n",
       "3  tt0137523      David Fincher   \n",
       "4  tt0109830    Robert Zemeckis   \n",
       "\n",
       "                                            writer imdb_rating  \\\n",
       "0                      Stephen King;Frank Darabont         9.3   \n",
       "1  David S. Goyer;Jonathan Nolan;Christopher Nolan         9.0   \n",
       "2                                Christopher Nolan         8.8   \n",
       "3                         Jim Uhls;Chuck Palahniuk         8.8   \n",
       "4                          Winston Groom;Eric Roth         8.8   \n",
       "\n",
       "  imdb_rating_count metascore user_review_count critic_review_count  color  \\\n",
       "0           2506833        80              9750                 190  Color   \n",
       "1           2456425        84              7764                 427    NaN   \n",
       "2           2203914        74              4466                 479  Color   \n",
       "3           1971788        66              4127                 366  Color   \n",
       "4           1934719        82              2807                 164  Color   \n",
       "\n",
       "  aspect_ratio  \n",
       "0     1.85 : 1  \n",
       "1     2.39 : 1  \n",
       "2     2.39 : 1  \n",
       "3     2.39 : 1  \n",
       "4     2.39 : 1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"data/scraped_df_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping people data <a class=\"anchor\" id=\"chapter5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned previously, TMDB API doesn't provide much data about the people who worked on a film, so we'll need to scrape that data ourselves. These pieces of info aren't located in the regular film pages but in the \"Full cast and crew\" pages. So before scraping the data we first need to collect all these pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "crew_pages = []\n",
    "\n",
    "for i in range(len(film_ids)):\n",
    "    crew_page = f'https://www.imdb.com/title/{film_ids[i]}/fullcredits/?ref_=tt_cl_sm'\n",
    "    crew_pages.append(crew_page) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions <a class=\"anchor\" id=\"subparagraph3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQtgCMgbUgCS"
   },
   "source": [
    "### Full cast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of the artists can be found inside the table with the \"cast-list\" class: they're the alternative text of the images inside the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_actors(soup):\n",
    "    \n",
    "    try:   \n",
    "        images = soup.find(\"table\", class_=\"cast_list\").find_all(\"img\") \n",
    "        \n",
    "        actors = [img.get(\"alt\") for img in images]  \n",
    "        \n",
    "        actors = ';'.join(actors)\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "    \n",
    "    else:\n",
    "        return actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cinematographer, editor, composer, producers, production designer, art director, costume designer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function scrapes the names of different types of artists. The type must be specified in the 'artist' argument. \n",
    "\n",
    "In the \"Full Cast & Crew\" pages each artist type has its own table element containing the names of the artists. Each of these tables is preceded by an h4 element with an id equal to the artist type. For example, the name of the cinematographer is contained in the table preceded by the h4 element with id equal to \"cinematographer\". To scrape this data, we'll first access the h4 element, then we'll access the table next to it and finally we'll get all the names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_artist(soup, artist):\n",
    "    \n",
    "    try:\n",
    "        h = soup.find(\"h4\", id = artist)\n",
    "        \n",
    "        a_tags = h.find_next(\"table\").find_all(\"a\")\n",
    "        \n",
    "        artists = [a.text.lstrip().replace('\\n', '') for a in a_tags]\n",
    "        \n",
    "        artists = ';'.join(artists)\n",
    "    \n",
    "    except:\n",
    "        return np.nan\n",
    "        \n",
    "    else:     \n",
    "        return artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the dataframe <a class=\"anchor\" id=\"subparagraph4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the second dataframe of scraped data, we'll build a function very similar to the one we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_scraped_df_2(urls):\n",
    "    \n",
    "    df = pd.DataFrame(columns = [\"id\", \"actors\", \"cinematographer\", \"editor\", \"composer\", \"producers\", \"production_designer\",\n",
    "                                \"art_director\", \"costume_designer\"])\n",
    "    \n",
    "    for url in urls:\n",
    "        session = requests.Session()\n",
    "        retry = Retry(total = 30, backoff_factor = 0.000001)\n",
    "        adapter = HTTPAdapter(max_retries=retry)\n",
    "        session.mount('http://', adapter)\n",
    "        session.mount('https://', adapter)\n",
    "        \n",
    "        content = session.get(url).content\n",
    "        soup = BeautifulSoup(content)\n",
    "            \n",
    "        df = df.append({\"id\": re.findall(r\"tt\\d+\", url)[0],\n",
    "                        \"actors\": scrape_actors(soup),\n",
    "                        \"cinematographer\": scrape_artist(soup, \"cinematographer\"),\n",
    "                        \"editor\": scrape_artist(soup, \"editor\"),\n",
    "                        \"composer\": scrape_artist(soup, \"composer\"),\n",
    "                        \"producers\": scrape_artist(soup, \"producer\"),\n",
    "                        \"production_designer\": scrape_artist(soup, \"production_designer\"),\n",
    "                        \"art_director\": scrape_artist(soup, \"art_director\"),\n",
    "                        \"costume_designer\": scrape_artist(soup, \"costume_designer\")},\n",
    "                        ignore_index = True)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run it on our list of 'Full cast and crew' pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = build_scraped_df_2(crew_pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>actors</th>\n",
       "      <th>cinematographer</th>\n",
       "      <th>editor</th>\n",
       "      <th>composer</th>\n",
       "      <th>producers</th>\n",
       "      <th>production_designer</th>\n",
       "      <th>art_director</th>\n",
       "      <th>costume_designer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>Tim Robbins;Morgan Freeman;Bob Gunton;William ...</td>\n",
       "      <td>Roger Deakins</td>\n",
       "      <td>Richard Francis-Bruce</td>\n",
       "      <td>Thomas Newman</td>\n",
       "      <td>Liz Glotzer;David V. Lester;Niki Marvin</td>\n",
       "      <td>Terence Marsh;Soheil</td>\n",
       "      <td>Peter Landsdown Smith</td>\n",
       "      <td>Elizabeth McBride</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>Christian Bale;Heath Ledger;Aaron Eckhart;Mich...</td>\n",
       "      <td>Wally Pfister</td>\n",
       "      <td>Lee Smith</td>\n",
       "      <td>James Newton Howard;Hans Zimmer</td>\n",
       "      <td>Kevin de la Noy;Jordan Goldberg;Philip Lee;Ben...</td>\n",
       "      <td>Nathan Crowley</td>\n",
       "      <td>Mark Bartholomew;James Hambidge;Craig Jackson;...</td>\n",
       "      <td>Lindy Hemming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Leonardo DiCaprio;Joseph Gordon-Levitt;Elliot ...</td>\n",
       "      <td>Wally Pfister</td>\n",
       "      <td>Lee Smith</td>\n",
       "      <td>Hans Zimmer</td>\n",
       "      <td>Zakaria Alaoui;John Bernard;Chris Brigham;Jord...</td>\n",
       "      <td>Guy Hendrix Dyas</td>\n",
       "      <td>Luke Freeborn;Matthew Gray;Brad Ricker;Dean Wo...</td>\n",
       "      <td>Jeffrey Kurland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0137523</td>\n",
       "      <td>Edward Norton;Brad Pitt;Meat Loaf;Zach Grenier...</td>\n",
       "      <td>Jeff Cronenweth</td>\n",
       "      <td>James Haygood</td>\n",
       "      <td>Dust Brothers;John King;Michael Simpson</td>\n",
       "      <td>Ross Grayson Bell;Ceán Chaffin;John S. Dorsey;...</td>\n",
       "      <td>Alex McDowell</td>\n",
       "      <td>Melique Berger;Chris Gorak</td>\n",
       "      <td>Michael Kaplan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Tom Hanks;Rebecca Williams;Sally Field;Michael...</td>\n",
       "      <td>Don Burgess</td>\n",
       "      <td>Arthur Schmidt</td>\n",
       "      <td>Alan Silvestri</td>\n",
       "      <td>Wendy Finerman;Charles Newirth;Steve Starkey;S...</td>\n",
       "      <td>Rick Carter</td>\n",
       "      <td>Leslie McDonald;William James Teegarden</td>\n",
       "      <td>Joanna Johnston</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                             actors  \\\n",
       "0  tt0111161  Tim Robbins;Morgan Freeman;Bob Gunton;William ...   \n",
       "1  tt0468569  Christian Bale;Heath Ledger;Aaron Eckhart;Mich...   \n",
       "2  tt1375666  Leonardo DiCaprio;Joseph Gordon-Levitt;Elliot ...   \n",
       "3  tt0137523  Edward Norton;Brad Pitt;Meat Loaf;Zach Grenier...   \n",
       "4  tt0109830  Tom Hanks;Rebecca Williams;Sally Field;Michael...   \n",
       "\n",
       "   cinematographer                 editor  \\\n",
       "0    Roger Deakins  Richard Francis-Bruce   \n",
       "1    Wally Pfister              Lee Smith   \n",
       "2    Wally Pfister              Lee Smith   \n",
       "3  Jeff Cronenweth          James Haygood   \n",
       "4      Don Burgess         Arthur Schmidt   \n",
       "\n",
       "                                  composer  \\\n",
       "0                            Thomas Newman   \n",
       "1          James Newton Howard;Hans Zimmer   \n",
       "2                              Hans Zimmer   \n",
       "3  Dust Brothers;John King;Michael Simpson   \n",
       "4                           Alan Silvestri   \n",
       "\n",
       "                                           producers   production_designer  \\\n",
       "0            Liz Glotzer;David V. Lester;Niki Marvin  Terence Marsh;Soheil   \n",
       "1  Kevin de la Noy;Jordan Goldberg;Philip Lee;Ben...        Nathan Crowley   \n",
       "2  Zakaria Alaoui;John Bernard;Chris Brigham;Jord...      Guy Hendrix Dyas   \n",
       "3  Ross Grayson Bell;Ceán Chaffin;John S. Dorsey;...         Alex McDowell   \n",
       "4  Wendy Finerman;Charles Newirth;Steve Starkey;S...           Rick Carter   \n",
       "\n",
       "                                        art_director   costume_designer  \n",
       "0                              Peter Landsdown Smith  Elizabeth McBride  \n",
       "1  Mark Bartholomew;James Hambidge;Craig Jackson;...      Lindy Hemming  \n",
       "2  Luke Freeborn;Matthew Gray;Brad Ricker;Dean Wo...    Jeffrey Kurland  \n",
       "3                         Melique Berger;Chris Gorak     Michael Kaplan  \n",
       "4            Leslie McDonald;William James Teegarden    Joanna Johnston  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('data/scraped_df_2.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Building a database of IMDB 10,000 most popular feature films.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.837px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
