{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- capire come scrapare meglio user review counts\n",
    "- (scrape link full cast);\n",
    "- (creare funzione per cinematographer, writers, editor e composer);\n",
    "- (creare funzione per scrapare people);\n",
    "- join df, df2, (df3)\n",
    "- pulizia dati (contare nulle, casting)\n",
    "- nascondere api key\n",
    "- aggiungere table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imOzibmru9uI"
   },
   "source": [
    "# Project description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XdfhPC5SvHKE"
   },
   "source": [
    "The goal of this project is to build a database of the 10 000 most popular feature films on IMDB. We'll define \"popularity\" as the number of ratings a film has received. \n",
    "\n",
    "The project will comprise the following steps:\n",
    "\n",
    "- collecting the data through scraping and API requests;\n",
    "- loading the data onto a PostgreSQL database;\n",
    "- querying the database with SQL;\n",
    "- visualizing the output of the queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGNNMM5OucPo"
   },
   "source": [
    "# Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Tq5zlLcDuCkM"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GySk7pbunwY"
   },
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-6kyKK3UprX"
   },
   "source": [
    "IMDB doesn't have an official API. However, there are two unofficial APIs providing access to IMDB data: The Open Movie Database (OMDb) and The Movie Database (TMDB). In this project we'll rely on the latter as it doesn't enforce a rate limit. We're also going to supplement the API data with scraped data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jt0ZSUT3Xm3o"
   },
   "source": [
    "The TMDB API works by supplying the ID of the film(s) whose info we'd like to retrieve. The IDs consist of a double \"t\" followed by seven or eight digits. They can be found inside a film URL. For example, \"tt0050782\" is the ID for this film: https://www.imdb.com/title/tt0050782/. \n",
    "\n",
    "The first step will thus be retrieving the IDs of the 10 000 most popular films on IMDB, which can be found in this [playlist](https://www.imdb.com/search/keyword/?mode=detail&page=1&title_type=movie&ref_=kw_ref_rt_vt&num_votes=5000%2C&sort=num_votes,desc)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruIEsF-V4A7N"
   },
   "source": [
    "## Scraping the film IDs and the URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN3DXnxMYrbc"
   },
   "source": [
    "To scrape the film IDs of our 10 000 films we'll need to iterate a for loop over the first 200 pages in the playlist (each containing 50 films). The film ID is the value of the 'href' attribute inside h3 elements with the \"lister-item-header\" class. We'll write a simple regex to extract the film ID. We'll also scrape the entire URL: it's going to come in handy later when we do the scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N0QXTJHZwTUc"
   },
   "outputs": [],
   "source": [
    "film_ids = []\n",
    "film_urls = []\n",
    "\n",
    "for i in range(1, 201):\n",
    "  \n",
    "  content = requests.get(\"https://www.imdb.com/search/keyword/?mode=detail&page=\" + str(i) + \"&title_type=movie&ref_=kw_ref_rt_vt&num_votes=5000%2C&sort=num_votes,desc\").content\n",
    "  \n",
    "  soup = BeautifulSoup(content)\n",
    "\n",
    "  for film in soup.find_all(\"h3\", class_=\"lister-item-header\"):\n",
    "\n",
    "    link = film.find(\"a\").get(\"href\")\n",
    "    film_id = re.findall(pattern = r\"tt\\d+\", string = link)[0]\n",
    "    film_ids.append(film_id)\n",
    "\n",
    "    film_url = \"https://www.imdb.com\" + link\n",
    "    film_urls.append(film_url)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3GwT4Wuv61we"
   },
   "source": [
    "## API calls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51KySz-jZsxT"
   },
   "source": [
    "We'll now write a function to request the data from TMDB. The function takes a vector of film IDs and for each ID it sends a GET request to the API. If the status code is equal to 200 (i.e. the request has been successful) we'll append the data to a Pandas dataframe. Otherwise, we'll just append the film_id and we'll fill the remaining columns with null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pn5hoWsWdNZZ"
   },
   "outputs": [],
   "source": [
    "def build_film_df(film_ids):\n",
    "\n",
    "  df = pd.DataFrame(columns = [\"id\", \"title\", \"release_date\", \"runtime\", \"country\", \"language\", \"genre\", \"studios\", \"budget\", \"revenue\"])\n",
    "\n",
    "  for film_id in film_ids:\n",
    "      \n",
    "      response = requests.get(\"https://api.themoviedb.org/3/movie/\" + film_id + \"?api_key=eb74f269207d7563d10da8190e228f61\")\n",
    "\n",
    "      if response.status_code == 200:  \n",
    "\n",
    "        response_json = response.json()\n",
    "\n",
    "        df = df.append({\"id\": response_json[\"imdb_id\"],\n",
    "                      \"title\": response_json[\"title\"],\n",
    "                      \"release_date\": response_json[\"release_date\"],\n",
    "                      \"runtime\": response_json[\"runtime\"],\n",
    "                      \"country\": ';'.join([country['name'] for country in response_json[\"production_countries\"]]),\n",
    "                      \"language\": ';'.join([language[\"english_name\"] for language in response_json[\"spoken_languages\"]]),\n",
    "                      \"genre\": ';'.join([genre[\"name\"] for genre in response_json[\"genres\"]]),\n",
    "                      \"studios\": ';'.join([company[\"name\"] for company in response_json['production_companies']]),\n",
    "                      \"budget\": response_json['budget'],\n",
    "                      \"revenue\": response_json[\"revenue\"]}, \n",
    "                       ignore_index = True)\n",
    "        \n",
    "      else:\n",
    "        df = df.append({\"id\": film_id}, ignore_index = True)\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "id": "ckKclT-ouHfd",
    "outputId": "d438579e-4d83-4c41-aad8-e53f0c02135b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>studios</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt0111161</td>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994-09-23</td>\n",
       "      <td>142</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama;Crime</td>\n",
       "      <td>Castle Rock Entertainment</td>\n",
       "      <td>25000000</td>\n",
       "      <td>28341469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt0468569</td>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008-07-14</td>\n",
       "      <td>152</td>\n",
       "      <td>United Kingdom;United States of America</td>\n",
       "      <td>English;Mandarin</td>\n",
       "      <td>Drama;Action;Crime;Thriller</td>\n",
       "      <td>DC Comics;Legendary Pictures;Syncopy;Isobel Gr...</td>\n",
       "      <td>185000000</td>\n",
       "      <td>1004558444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tt1375666</td>\n",
       "      <td>Inception</td>\n",
       "      <td>2010-07-15</td>\n",
       "      <td>148</td>\n",
       "      <td>United Kingdom;United States of America</td>\n",
       "      <td>English;Japanese</td>\n",
       "      <td>Action;Science Fiction;Adventure</td>\n",
       "      <td>Legendary Pictures;Syncopy;Warner Bros. Pictures</td>\n",
       "      <td>160000000</td>\n",
       "      <td>825532764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt0137523</td>\n",
       "      <td>Fight Club</td>\n",
       "      <td>1999-10-15</td>\n",
       "      <td>139</td>\n",
       "      <td>Germany;United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Drama</td>\n",
       "      <td>Regency Enterprises;Fox 2000 Pictures;Taurus F...</td>\n",
       "      <td>63000000</td>\n",
       "      <td>100853753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt0109830</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994-07-06</td>\n",
       "      <td>142</td>\n",
       "      <td>United States of America</td>\n",
       "      <td>English</td>\n",
       "      <td>Comedy;Drama;Romance</td>\n",
       "      <td>Paramount;The Steve Tisch Company</td>\n",
       "      <td>55000000</td>\n",
       "      <td>677387716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                     title release_date runtime  \\\n",
       "0  tt0111161  The Shawshank Redemption   1994-09-23     142   \n",
       "1  tt0468569           The Dark Knight   2008-07-14     152   \n",
       "2  tt1375666                 Inception   2010-07-15     148   \n",
       "3  tt0137523                Fight Club   1999-10-15     139   \n",
       "4  tt0109830              Forrest Gump   1994-07-06     142   \n",
       "\n",
       "                                   country          language  \\\n",
       "0                 United States of America           English   \n",
       "1  United Kingdom;United States of America  English;Mandarin   \n",
       "2  United Kingdom;United States of America  English;Japanese   \n",
       "3         Germany;United States of America           English   \n",
       "4                 United States of America           English   \n",
       "\n",
       "                              genre  \\\n",
       "0                       Drama;Crime   \n",
       "1       Drama;Action;Crime;Thriller   \n",
       "2  Action;Science Fiction;Adventure   \n",
       "3                             Drama   \n",
       "4              Comedy;Drama;Romance   \n",
       "\n",
       "                                             studios     budget     revenue  \n",
       "0                          Castle Rock Entertainment   25000000    28341469  \n",
       "1  DC Comics;Legendary Pictures;Syncopy;Isobel Gr...  185000000  1004558444  \n",
       "2   Legendary Pictures;Syncopy;Warner Bros. Pictures  160000000   825532764  \n",
       "3  Regency Enterprises;Fox 2000 Pictures;Taurus F...   63000000   100853753  \n",
       "4                  Paramount;The Steve Tisch Company   55000000   677387716  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = build_film_df(film_ids)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZmSWuoY8zvF"
   },
   "source": [
    "Let's have a look at the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "9Z4dClmq8WuR",
    "outputId": "3efdddf4-1f69-4614-b5c4-2a02803f79f0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>release_date</th>\n",
       "      <th>runtime</th>\n",
       "      <th>country</th>\n",
       "      <th>language</th>\n",
       "      <th>genre</th>\n",
       "      <th>studios</th>\n",
       "      <th>budget</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5241</th>\n",
       "      <td>tt9573980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9128</th>\n",
       "      <td>tt8075016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>tt13423846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id title release_date runtime country language genre studios  \\\n",
       "5241   tt9573980   NaN          NaN     NaN     NaN      NaN   NaN     NaN   \n",
       "9128   tt8075016   NaN          NaN     NaN     NaN      NaN   NaN     NaN   \n",
       "9978  tt13423846   NaN          NaN     NaN     NaN      NaN   NaN     NaN   \n",
       "\n",
       "     budget revenue  \n",
       "5241    NaN     NaN  \n",
       "9128    NaN     NaN  \n",
       "9978    NaN     NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['title'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VroIT9ExpVtY"
   },
   "source": [
    "## Scraping additional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOgUWYm7bRqV"
   },
   "source": [
    "TMDB doesn't provide data about the people who worked on a film (directors, writer, actors etc.) and its rating data is inaccurate. We'll thus integrate the data we just got by scraping some more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AdfF63LCTwRi"
   },
   "source": [
    "### Custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KytHOgpT0HC"
   },
   "source": [
    "To implement sound software engineering principles we'll scrape the data by building a function for each type of data we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdS235LCUFDf"
   },
   "source": [
    "#### Film ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nNSWeewsQ3Gt"
   },
   "outputs": [],
   "source": [
    "def scrape_film_id(soup):\n",
    "  \n",
    "  return soup.find(\"meta\", {\"property\": \"imdb:pageConst\"}).get(\"content\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0WpHvI39UHtL"
   },
   "source": [
    "#### Directors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "zwLDT6CW1tL0"
   },
   "outputs": [],
   "source": [
    "def scrape_director(soup):\n",
    "    \n",
    "    a_tags = soup.find_all(href = re.compile(\"tt_ov_dr\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "    \n",
    "    directors = list(set([a.text for a in a_tags]))\n",
    "    \n",
    "    return ';'.join(directors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_writer(soup):\n",
    "    \n",
    "  a_tags = soup.find_all(href = re.compile(\"tt_ov_wr\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "  \n",
    "  writers = list(set([a.text for a in a_tags]))\n",
    "\n",
    "  return ';'.join(writers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_actors(soup):\n",
    "    \n",
    "    a_tags = soup.find_all(href = re.compile(\"tt_ov_st\"), class_=\"ipc-metadata-list-item__list-content-item ipc-metadata-list-item__list-content-item--link\")\n",
    "\n",
    "    actors = list(set([a.text for a in a_tags]))\n",
    "\n",
    "    return ';'.join(actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mY0xRacoUKxG"
   },
   "source": [
    "#### IMDB average rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GHuWP7Pe8EHq"
   },
   "outputs": [],
   "source": [
    "def scrape_imdb_rating(soup):\n",
    "  \n",
    "  pattern = r'(?<=\"ratingValue\":)[\\d.]+(?=},\"contentRating\")'\n",
    "  string = str(soup.find(\"script\", {\"type\": \"application/ld+json\"}))\n",
    "\n",
    "  return re.findall(pattern = pattern,\n",
    "                    string = string)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63sBX-TwUN1q"
   },
   "source": [
    "#### IMDB rating count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "7u68JHWr_1oe"
   },
   "outputs": [],
   "source": [
    "def scrape_rating_count(soup):\n",
    "\n",
    "  pattern = r'(?<=\"ratingCount\":)[\\d.]+'\n",
    "  string = str(soup.find(\"script\", {\"type\": \"application/ld+json\"}))\n",
    "\n",
    "  return re.findall(pattern = pattern,\n",
    "                    string = string)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ne8ybLy_UPrk"
   },
   "source": [
    "#### Metascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HzWpD51AAhe5"
   },
   "outputs": [],
   "source": [
    "def scrape_metascore(soup):\n",
    "\n",
    "  return soup.find(\"span\", class_=\"score-meta\").text if soup.find(\"span\", class_=\"score-meta\") else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YwH147RUSXB"
   },
   "source": [
    "#### User reviews count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PLb_JqIRnKls"
   },
   "outputs": [],
   "source": [
    "def scrape_user_review_count(soup):\n",
    "  \n",
    "  pattern = r'(?<=\"total\":)\\d+(?=,\"__typename\":\"ReviewsConnection\"},\"criticReviewsTotal\":)'\n",
    "  \n",
    "  string = str(soup.find(\"script\", {'id': '__NEXT_DATA__'}))\n",
    "  \n",
    "  return re.findall(pattern = pattern, string = string)[0] if re.findall(pattern = pattern, string = string) else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0WXIPIWUWHl"
   },
   "source": [
    "#### Critic reviews count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_critic_review_count(soup):\n",
    "    \n",
    "    string = list(filter(lambda x: 'Critic' in str(x), soup.find_all(\"span\", class_=\"three-Elements\")))[0].text\n",
    "    \n",
    "    return re.findall(r'\\d+', string)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_color(soup):\n",
    "    \n",
    "    pattern = r'(?<=\"text\":\")\\w+(?=\",\"attributes\":\\[\\],\"__typename\":\"Coloration\"})'\n",
    "    \n",
    "    string = str(soup.find(\"script\", {\"type\": \"application/json\"}))\n",
    "    \n",
    "    return re.findall(pattern = pattern, string = string)[0] if re.findall(pattern = pattern, string = string) else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aspect ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_aspect_ratio(soup):\n",
    "    \n",
    "    pattern = r'(?<=\"aspectRatio\":\")[\\d.\\s:]+'\n",
    "    \n",
    "    string = str(soup.find(\"script\", {\"type\": \"application/json\"}))\n",
    "    \n",
    "    return re.findall(pattern = pattern, string = string)[0] if re.findall(pattern = pattern, string = string) else np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRaqDP82V4Xh"
   },
   "source": [
    "### Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we send 10 000 requests at once we're likely going to run into problems with IMDB, so let's split the film_urls list into 5 equally-sized chunks and let's scrape each chunk at a time by waiting five minutes before moving to the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "-PuxtrS5V8IQ"
   },
   "outputs": [],
   "source": [
    "def build_scraped_df(urls):\n",
    "\n",
    "  df = pd.DataFrame(columns = [\"id\", \"director\", \"imdb_rating\", \"imdb_rating_count\", \"metascore\", \n",
    "                               \"user_review_count\", \"critic_review_count\", \"color\", \"aspect_ratio\"])\n",
    "\n",
    "  chunks = np.array_split(urls, 5)\n",
    "\n",
    "  for chunk in chunks:\n",
    "    for url in chunk:\n",
    "      content = requests.get(url).content\n",
    "      soup = BeautifulSoup(content)\n",
    "\n",
    "      df = df.append({\"id\": scrape_film_id(soup),\n",
    "                      \"director\": scrape_director(soup),\n",
    "                      \"imdb_rating\": scrape_imdb_rating(soup),\n",
    "                      \"imdb_rating_count\": scrape_rating_count(soup),\n",
    "                      \"metascore\": scrape_metascore(soup),\n",
    "                      \"user_review_count\": scrape_user_review_count(soup),\n",
    "                      \"critic_review_count\": scrape_critic_review_count(soup),\n",
    "                      \"color\": scrape_color(soup),\n",
    "                      \"aspect_ratio\": scrape_aspect_ratio(soup)}, \n",
    "                      ignore_index = True)\n",
    "\n",
    "    time.sleep(60*5)\n",
    "\n",
    "  return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Sqmef_HbZ6fi",
    "outputId": "a5e98cbb-4ae7-4444-9e39-bfe70225c3d4"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ee732d91d8de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_scraped_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilm_urls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-184d5c348976>\u001b[0m in \u001b[0;36mbuild_scraped_df\u001b[1;34m(urls)\u001b[0m\n\u001b[0;32m     15\u001b[0m                       \u001b[1;34m\"imdb_rating\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscrape_imdb_rating\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                       \u001b[1;34m\"imdb_rating_count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscrape_rating_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m                       \u001b[1;34m\"metascore\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscrape_metascore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m                       \u001b[1;34m\"user_review_count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscrape_user_review_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                       \u001b[1;34m\"critic_review_count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mscrape_critic_review_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-0dc999b698e8>\u001b[0m in \u001b[0;36mscrape_metascore\u001b[1;34m(soup)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mscrape_metascore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"span\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"score-meta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "df2 = build_scraped_df(film_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "Sqmef_HbZ6fi",
    "outputId": "a5e98cbb-4ae7-4444-9e39-bfe70225c3d4"
   },
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting the null values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.apply(lambda x: x.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is each id unique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qQtgCMgbUgCS"
   },
   "source": [
    "#### Full cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-vthpeyJ1_n"
   },
   "outputs": [],
   "source": [
    "def scrape_actors(soup):\n",
    "  \n",
    "  actors = [img.get(\"alt\") for img in soup.find(\"table\", class_=\"cast_list\").find_all(\"img\")]\n",
    "  return ';'.join(actors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHuYXHjmFdnU"
   },
   "source": [
    "# Load the data onto a database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TeXDWGQvFiU2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Building a database of IMDB 10,000 most popular feature films.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
